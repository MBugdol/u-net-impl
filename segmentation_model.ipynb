{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiutils import CamouflagedAnimalsModel\n",
    "from dataset import CamouflagedAnimalsDataset, colorMaskToOneHot\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "import torch as T\n",
    "from torchvision.transforms import v2 as TV\n",
    "\n",
    "from torchview import draw_graph\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "class VisualizeModel(Callback):\n",
    "    def on_train_batch_start(self, trainer, pl_module, batch, batch_idx):\n",
    "        # transforms = [ hl.transforms.Prune('Constant') ]\n",
    "        \n",
    "        # graph = hl.build_graph(pl_module, batch[0], transforms=transforms)\n",
    "        # print(hl.graph.THEMES)\n",
    "        # graph.theme = hl.graph.THEMES[\"blue\"].copy()\n",
    "        # graph.save(\"model_graph\", format=\"png\")\n",
    "        pass\n",
    "        \n",
    "\n",
    "# enable TPU\n",
    "T.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "\n",
    "# checkpoint = \"lightning_logs/version_17/checkpoints/epoch=16-step=289.ckpt\"\n",
    "checkpoint = None\n",
    "\n",
    "if checkpoint is None:\n",
    "    model_lightning = CamouflagedAnimalsModel()\n",
    "else:\n",
    "    model_lightning = CamouflagedAnimalsModel.load_from_checkpoint(checkpoint)\n",
    "\n",
    "common_transform = TV.Compose(\n",
    "    [\n",
    "        TV.RandomHorizontalFlip(0.5),\n",
    "        TV.Resize((256, 256), interpolation=TV.InterpolationMode.NEAREST),\n",
    "        TV.ToDtype(T.float, scale=True),\n",
    "    ]\n",
    ")\n",
    "image_transform = TV.Compose(\n",
    "    [TV.ColorJitter(brightness=0.3, hue=0.15), TV.RandomEqualize(0.5)]\n",
    ")\n",
    "mask_transform = TV.Compose([colorMaskToOneHot])\n",
    "\n",
    "dataset = CamouflagedAnimalsDataset(\n",
    "    images_path=\"images\",\n",
    "    masks_path=\"masks\",\n",
    "    common_transform=common_transform,\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform,\n",
    ")\n",
    "seed = T.Generator().manual_seed(42)\n",
    "train_set, valid_set = T.utils.data.random_split(dataset, [0.9, 0.1], generator=seed)\n",
    "train_loader = T.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=15,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "graph = draw_graph(model_lightning, input_size=(20,3,512,512), expand_nested=True)\n",
    "graph.visual_graph.render(format='png')\n",
    "\n",
    "valid_loader = T.utils.data.DataLoader(\n",
    "    valid_set,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    limit_train_batches=250,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    max_epochs=9999,\n",
    "    callbacks=[ModelSummary(max_depth=2), VisualizeModel()],\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=model_lightning,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=valid_loader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
